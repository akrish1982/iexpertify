<html><head><link href="../../simplecss/styles.css" rel="stylesheet"/>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3040480045347797"
     crossorigin="anonymous"></script>
</head></html><!DOCTYPE html>






Netezza Design for better Performance - learn learn


Reading Time:  4 minutes
 
we will cover these topics: 
<a class="lwptoc_toggle_label" data-label="show" href="index.html#">hide</a>



 <a href="index.html#Considerations_for_better_performance">
1)
Considerations for better performance:
</a>
 <a href="index.html#Distribution">
1.1)
Distribution
</a>
 <a href="index.html#Statistics">
1.2)
Statistics
</a>
 <a href="index.html#Zone_maps">
1.3)
Zone maps
</a>
 <a href="index.html#Clustered_base_tables">
1.4)
Clustered base tables
</a>
 <a href="index.html#Groom_table_command">
1.5)
Groom table command
</a>
 <a href="index.html#Performance_Issues">
2)
Performance Issues:
</a>
 <a href="index.html#The_following_are_some_of_the_common_reasons_for_performance_issues">
2.1)
The following are some of the common reasons for performance issues
</a>
 <a href="index.html#Steps_to_do_query_performance_analysis">
2.2)
Steps to do query performance analysis
</a>
 <a href="index.html#What_to_read_next">
2.3)
What to read next?
</a>

<h2>Considerations for better performance:</h2>
<h3>Distribution</h3>
<p class="has-cyan-bluish-gray-background-color has-background">Bad distribution cause the data skew (more data stored in certain data slices while less data is stored in other data slices). That affects the query in hand and others as the data slice has more work to do. Consider distributing on random if you don‚Äôt know the right distribution key.Data types</p>
<p>It is important to select a data type that will minimize disk storage requirements and minimize scan time. The right choosing right data type even reduce the disk I/O.¬†‚Ä¢ Use Char(x) instead of Varchar(x) when you expect the data to be a fixed length as this not only helps to save disk space but also helps performance due to reduced I/O (Varchar(x) uses additional storage which will be significant when dealing with TB of data and also impacts the query processing since additional data need to be pulled in from disk for processing).‚Ä¢ Where possible, use the NOT NULL constraint for columns in the tables, especially for columns that are used in where clauses (Restriction) or join conditions.¬† This will help improve performance by not having to check for null condition by the appliance and will reduce storage usage.¬†¬†</p>
<h3>Statistics</h3>
<p>The nzsql GENERATE STATISTICS command generates statistics about each table column‚Äôs proportion of stats, including duplicate values, maximum value, minimum value, null values, dispersion values and updates the system catalog table. The optimizer relies on GENERATE STATISTICS to gather statistics about the tables in the database to determine the most efficient way to execute a query. It is important that the optimizer always has high quality statistics to choose the best execution plan from all possible plans.</p>
<h3>Zone maps</h3>
<p>A zone map is an internal mapping structure to show the range (min and max) of values within each page. During scans, zone maps reduces I/O by skipping pages that did not qualify the query parameters. Zone maps are internal to the system thus no administration involved.</p>
<h3>Clustered base tables</h3>
<p>A Netezza clustered base tables (CBT) are user table that has data which is organized using one to four organizing keys columns. You can specify max four columns in organize on clause and those columns should not be a part of distribute on clause.</p>
<h3>Groom table command</h3>
<p>¬†Groom tables that receive frequent updates or deletes or if a load or insert is aborted as this will result in deleted rows. You can groom at a record level to remove all deleted records regardless of their location. This will give you the best space gains but take longer.</p>
<h2>Performance Issues:</h2>
<h3>The following are some of the common reasons for performance issues</h3>
<ul class="has-cyan-bluish-gray-background-color has-background"><li>Appropriate distribution keys ‚Äì may result in certain data slice storing more data resulting in data skew. Performance of a query depends on the performance of the slice storing the most data for the tables involved in a query.</li><li>If you have distributed the data uniformly, process skew could still happen when not taking into account processing patterns. For e.g. data is distributed by month but if the process looks for a month of data, then the performance of the query will be degraded since the processing needs to be handled by a subset of SPUs and not all of the SPUs in the system.</li><li>Performance gets impacted if a large volume of data (fact table) gets re-distributed or broadcast during query execution.</li><li>Considerations to have numeric datatypes for join columns and where clause columns wherever possible so that the Zone maps can be used. Generating the zone maps for the ones that automatically create Zone maps ‚Äì char, varchar etc.</li><li>Table data that isn‚Äôt organized optimally for multi table joins as in the case of multi- dimensional joins performed in a data warehouse environment.</li></ul>
<h3>Steps to do query performance analysis</h3>
<ul><li>Identify long running queries o Identify if queries are being queued and the long running queries which is causing the queries to be queued through NZAdmin tool or nzsession command. o Long running queries can also be identified if query history is being gathered using appropriate history configuration</li><li>For long running queries generate query plans using the ‚ÄúEXPLAIN‚Äù command. Recent query execution plans are also stored in *.pln files in the data.&lt;ver&gt;/plans directory under the /nz/data directory.</li><li>Look for some of the data points and reasons for performance issues details in the previous sections.</li><li>Take necessary actions like generate statistics, change distributions, grooming tables, creation of materialized views, modifying or using organization keys, changing column data types or rewriting query.</li><li>Verify whether the modifications helped with the query plan by regenerating the plan using the explain utility.</li><li>If the analysis is performed in a non-development environment, it is key to make sure that the statistics reflect the values expected or in production.</li></ul>

<br><br>
<h3>Meet Ananth Tirumanur. Hi there üëã</h3>

    <h4>I work on projects in data science, big data, data engineering, data modeling, software engineering, and system design.</h4>

    <ul>
        <li>üë®‚Äçüíª All of my projects are available at <a href="https://github.com/akrish1982">https://github.com/akrish1982</a></li>
        <li>üí¨ Ask me about <strong>Data engineering, SQL, Databases, Data pipelines, Data infrastructure</strong></li>
        <li>üìÑ My work history: <a href="https://www.linkedin.com/in/ananthtirumanur/">https://www.linkedin.com/in/ananthtirumanur/</a></li>
        <li>‚ö° Fun fact: Marathoner & Casual Birding enthusiast</li>
    </ul>

    <h3>Connect with me:</h3>
    <ul>
        <li>Twitter: <a href="https://twitter.com/akrish82">@akrish82</a></li>
        <li>LinkedIn: <a href="https://linkedin.com/in/ananthtirumanur/">https://linkedin.com/in/ananthtirumanur/</a></li>
    </ul>

<h3>My Resources:</h3>
    <ul>
        <li>LinkedIn Newsletter: <a href="https://www.linkedin.com/newsletters/data-engineering-with-aws-7096111313352880128/">Data Engineering with AWS</a></li>
        <li>Udemy Course: <a href="https://www.udemy.com/course/aws-certified-data-engineer-associate-practice-test/learn/quiz/6218524#overview">AWS Certified Data Engineer Associate Practice Test</a></li>
        <li>Python Crash Course: <a href="https://akrish82.gumroad.com/l/python-crash-course">Python Crash Course on Gumroad</a></li>
    </ul>

    <h3>Languages and Tools:</h3>
    <p>AWS, Bash, Cassandra, Django, Docker, Elasticsearch, Flask, Git, Go, Grafana, Hadoop, Hive, Hugo, Kafka, Kubernetes, Linux, MariaDB, MySQL, Pandas, PostgreSQL, Python, Redis, Scala, Scikit-learn, SQLite</p>





 





 
 






