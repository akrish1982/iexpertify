<html><head><link href="/simplecss/styles.css" rel="stylesheet"/>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3040480045347797"
     crossorigin="anonymous"></script>
     <script
    src="https://topmate-embed.s3.ap-south-1.amazonaws.com/v1/topmate-embed.js"
    user-profile="https://topmate.io/embed/profile/ananth_tirumanur?theme=D5534D"
    btn-style='{"backgroundColor":"#000","color":"#fff","border":"1px solid #000"}'
    embed-version="v1"
    button-text="Let's Connect"
    position-right="30px"
    position-bottom="30px"
    custom-padding="0px"
    custom-font-size="16px"
    custom-font-weight="500"
    custom-width="200px"
    async=""
    defer=""
  ></script>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VS67BGEQZW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VS67BGEQZW');
</script>  
</head></html><!DOCTYPE html>
    <header>
        <nav>
            <ul>
                <li><a href="https://www.iexpertify.com/">iExpertify</a></li>
                <li><a href="https://www.iexpertify.com/free-utilities/">Free Utilities</a></li>
            </ul>
        </nav>
    </header>






Netezza storage - learn

Netezza storage disks
<p>The primary partition in each disk is used to store user data like database tables, the mirror stores a copy of the primary partition of another disk so that it can be used in the event of disk failures and the temp/swap partition is used to store the data temporarily like when the appliance does data redistribution while processing queries. The logical representation of the data saved in the primary partition of each disk is called the data slice. When users create database tables and loads data into it, they get distributed across the available data slices. Logical representation of data slices is called the data partition. </p>
<p>For TwinFin systems each S-Blade or SPU is connected to 8 data partitions and some only to 6 disk partitions (since some disks are reserved for failovers). There are situations like SPU failures when a SPU can have more than 8 partitions attached to it since it got assigned some of the data partitions from the failed SPU. </p>
<p>The SPU is connected to 8 data partitions numbered 0 to 7. Each data partition is connected to one data slice stored on different disks.</p>

<p>What happens when a disk fails â€“ Immediately after the disk stops responding, the disk with the mirror will be used by the system to satisfy queries for data from primary and mirror data. This will also create a bottleneck which in-turn impacts query performances. In the meantime, the contents in the failed disk Â is regenerated on one of the spare disks in the disk array. Once the regen is complete the SPU data partition is updated to point to the data slice on the new disk. The regen process removes the bottleneck of disk to perform optimally. In the situation where a SPU fails, the appliance assigns all the data partitions to other SPUs in the system. Pairs of disks which contains the mirror copy of each otherâ€™s data slice will be assigned to other SPUs which will result in additional two data partitioned to be managed by the target SPU.</p>


<br><br>
<h3>Meet Ananth Tirumanur. Hi there ğŸ‘‹</h3>

    <h4>I work on projects in data science, big data, data engineering, data modeling, software engineering, and system design.</h4>

    <ul>
        <li>ğŸ‘¨â€ğŸ’» All of my projects are available at <a href="https://github.com/akrish1982">https://github.com/akrish1982</a></li>
        <li>ğŸ’¬ Ask me about <strong>Data engineering, SQL, Databases, Data pipelines, Data infrastructure</strong></li>
        <li>ğŸ“„ My work history: <a href="https://www.linkedin.com/in/ananthtirumanur/">https://www.linkedin.com/in/ananthtirumanur/</a></li>
        <li>âš¡ Fun fact: Marathoner & Casual Birding enthusiast</li>
    </ul>
    <iframe height='160' width='300' frameborder='0' allowtransparency='true' scrolling='no' src='https://www.strava.com/athletes/42567926/activity-summary/6bbf7aabb6546e61f1317a54d973b259158da8a8'></iframe>


    <h3>Connect with me:</h3>
    <ul>
        <li>Twitter: <a href="https://twitter.com/akrish82">@akrish82</a></li>
        <li>LinkedIn: <a href="https://linkedin.com/in/ananthtirumanur/">https://linkedin.com/in/ananthtirumanur/</a></li>
    </ul>

<h3>My Resources:</h3>
    <ul>
        <li>LinkedIn Newsletter: <a href="https://www.linkedin.com/newsletters/data-engineering-with-aws-7096111313352880128/">Data Engineering with AWS</a></li>
        <li>Udemy Course: <a href="https://www.udemy.com/course/aws-certified-data-engineer-associate-practice-test/learn/quiz/6218524#overview">AWS Certified Data Engineer Associate Practice Test</a></li>
        <li>Python Crash Course: <a href="https://akrish82.gumroad.com/l/python-crash-course">Python Crash Course on Gumroad</a></li>
    </ul>

    <h3>Languages and Tools:</h3>
    <p>AWS, Bash, Docker, Elasticsearch, Git, Grafana, Hadoop, Hive, EMR, Glue, Athena, Lambda, Step Functions, Airflow/MWAA, DynamoDB, Kafka, Kubernetes, Linux, MariaDB, MySQL, Pandas, PostgreSQL, Python, Redis, Scala, SQLite</p>





 





 
 






