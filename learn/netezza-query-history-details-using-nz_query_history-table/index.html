<html><head>
<script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-VS67BGEQZW');</script>
</head><body><header><nav><ul><li><a href="https://www.iexpertify.com/">iExpertify</a></li><li><a href="https://www.iexpertify.com/free-utilities/">Free Utilities</a></li></ul></nav></header>


**Accessing Netezza Query History Details Using nz_query_history Table**

In this article, we will explore how to access Netezza query history details using the `nz_query_history` table. The `nz_query_history` table is a system catalog view that provides detailed information about SQL statements that have been executed against your Netezza system.

**Prerequisites**

Before we dive into the steps to access query history details, make sure you have the following:

1. Access to a Netezza database and appropriate privileges to query system tables.
2. A basic understanding of SQL.

**Accessing Query History Details**

Follow these steps to access query history details using the `nz_query_history` table:

**Step 1:** Connect to your Netezza database using a tool that supports running SQL queries, such as pgAdmin, Navicat for Netezza, or sqlcli.

**Step 2:** Execute the following query to retrieve query history details from the `nz_query_history` table:

```sql
SELECT * FROM nz_query_history WHERE job_id = 'your_job_id';
```
Replace 'your_job_id' with the actual job ID for the query you want to inspect. If you are interested in all queries executed within a specific timeframe, replace 'your_job_id' with the appropriate conditions (e.g., `WHERE start_time &gt;= 'start_date' AND start_time &lt;= 'end_date';`).

**Example Query Output**

Assuming you have run the query and fetched some results, the output will look similar to the following:

| job_id          | start_time                | end_time              | user_name           | application_name | num_rows_affected| num_bytes_read   | num_bytes_written| num_bytes_spilled| num_bytes_cached | status        |
|----------------|---------------------------|-----------------------|---------------------|--------------------|------------------|-------------------|------------------|------------------|-------------------|--------------|
| 1234567890      | 2022-03-01 09:00:01.000     | 2022-03-01 09:00:03.000 | john_doe            | psql               | 0                | 1024             | 0                | 0                | 0                 | success       |
| 876543210      | 2022-03-01 09:05:01.000     | 2022-03-01 09:05:05.000 | jane_doe            | psql               | 1000             | 8192             | 6400            | 0                | 1024           | success       |

**Columns Description**

Here's a brief explanation of each column in the `nz_query_history` table:

- job_id: The unique ID for the SQL statement.
- start_time and end_time: Timestamps indicating when the SQL statement started and finished execution, respectively.
- user_name: The username that submitted the SQL statement.
- application_name: The name of the application that submitted the SQL statement.
- num_rows_affected: The number of rows affected by the SQL statement (e.g., inserted, updated or deleted).
- num_bytes_read: The total bytes read from disk during the execution of the SQL statement.
- num_bytes_written: The total bytes written to disk during the execution of the SQL statement.
- num_bytes_spilled: The number of bytes spilled to disk (i.e., data that doesn't fit into memory).
- num_bytes_cached: The number of bytes cached in memory for future use.
- status: The execution status of the SQL statement, such as success or error.

**Conclusion**

Leveraging the `nz_query_history` table can help you monitor query performance, identify potential issues and optimize your Netezza database workloads more efficiently. By analyzing the data returned from this system catalog view, you can make informed decisions to improve overall system performance and optimize your queries for better results.

<footer>
<h3>Meet Ananth Tirumanur. Hi there üëã</h3>
<h4>I work on projects in data science, big data, data engineering, data modeling, software engineering, and system design.</h4>
<ul>
<li>üë®‚Äçüíª All of my projects are available at <a href="https://github.com/akrish1982">https://github.com/akrish1982</a></li>
<li>üí¨ Ask me about <strong>Data engineering, SQL, Databases, Data pipelines, Data infrastructure</strong></li>
<li>üìÑ My work history: <a href="https://www.linkedin.com/in/ananthtirumanur/">https://www.linkedin.com/in/ananthtirumanur/</a></li>
<li>‚ö° Fun fact: Marathoner &amp; Casual Birding enthusiast</li>
</ul>
<h3>Connect with me:</h3>
<ul>
<li>Twitter: <a href="https://twitter.com/akrish82">@akrish82</a></li>
<li>LinkedIn: <a href="https://linkedin.com/in/ananthtirumanur/">https://linkedin.com/in/ananthtirumanur/</a></li>
</ul>
<h3>My Resources:</h3>
<ul>
<li>LinkedIn Newsletter: <a href="https://www.linkedin.com/newsletters/data-engineering-with-aws-7096111313352880128/">Data Engineering with AWS</a></li>
<li>Udemy Course: <a href="https://www.udemy.com/course/aws-certified-data-engineer-associate-practice-test/learn/quiz/6218524#overview">AWS Certified Data Engineer Associate Practice Test</a></li>
<li>Python Crash Course: <a href="https://akrish82.gumroad.com/l/python-crash-course">Python Crash Course on Gumroad</a></li>
</ul>
<h3>Languages and Tools:</h3>
<p>AWS, Bash, Docker, Elasticsearch, Git, Grafana, Hadoop, Hive, EMR, Glue, Athena, Lambda, Step Functions, Airflow/MWAA, DynamoDB, Kafka, Kubernetes, Linux, MariaDB, MySQL, Pandas, PostgreSQL, Python, Redis, Scala, SQLite</p>
</footer>
</body></html>