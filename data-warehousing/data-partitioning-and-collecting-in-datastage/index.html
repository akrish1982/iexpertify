<html><head><link href="../../simplecss/styles.css" rel="stylesheet"/>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3040480045347797"
     crossorigin="anonymous"></script>
</head></html><!DOCTYPE html>






Data Partitioning and Collecting in DataStage - Data Warehousing Data Warehousing



Reading Time:  5 minutes
<p>Partitioning mechanism divides a portion of data into smaller segments, which is then processed independently by each node in parallel. It helps make a benefit of parallel architectures like SMP, MPP, Grid computing and Clusters.</p>
<p>Collecting is the opposite of partitioning and can be defined as a process of bringing back data partitions into a single sequential stream (one data partition).Â </p>

<p>Basically there are two methods or types of partitioning inÂ Datastage:</p>
<p>Key less Partitioning â€“ Partitioning is not based on the key column.</p>
<p>Key Based Partitioning â€“ Partitioning is based on the key column.</p>
<p>HashÂ â€“ In this method rows with same key column (or multiple columns) go to the same partition. Hash is very often used and sometimes improves performance, however it is important to have in mind that hash partitioning does not guarantee load balance and misuse may lead to skew data and poor performance.</p>
<p>Hash Partition guarantees that all records with same key column values are located in the same partition and are processed in the same node.Â </p>

<p>ModulusÂ â€“ In this method data is partitioned on one specified numeric field by calculating modulus against number of partitions. Not used very often.Â </p>
<p>RangeÂ â€“ This is an expensive refinement to hash partitioning. It is similar to hash butpartition mapping is user-determined and partitions are ordered. Rows are distributed according to the values in one or more key fields, using a range map (the â€˜Write Range Mapâ€™ stage needs to be used to create it). Range partitioning requires processing the data twice which makes it hard to find a reason for using it.</p>
<p>SameÂ â€“ Inthis method existing partitioning remains unchanged. No data is moved betweennodes. Carries the previous partitioning.</p>
<p>Round robinÂ â€“In this method rows are alternated evenly across partitions. This partitioningmethod guarantees an exact load balance (the same number of rows processed)between nodes and is very fast.</p>

<p>EntireÂ â€“ In this method all rows from a dataset are distributed to each partition. Duplicated rows are stored and the data volume is significantly increased.Â Allrecords goes through one node and mirror image is replicated to all othernodes.Â Never use this technique in case of funnel.</p>

<p>RandomÂ â€“ As the name suggests it randomly distribute the data across all over the partitions and ensures approximately equal sized partition. The random partitioning has a slightly higher overhead than round robin because of the extra processing required calculating a random value for each record.</p>
<p>AutoÂ â€“ default.</p>
<p>It chooses the best partitioning method depending on:</p>
<p>The mode of execution of the current stage and the precedingstage.</p>
<p>The number of nodes available in the configuration file.</p>
<p>Datastage Enterprise Edition decides between using Same or RoundRobin partitioning. Typically Same partitioning is used between two parallelstages and round robin is used between a sequential and an EE stage.</p>
<p>Data collecting methods:</p>
<p>A collector combines partitions into a single sequential stream.Â DatastageEE supports the following collecting algorithms:</p>
<p>Autoâ€“ the default algorithm reads rows from a partition as soonas they are ready. This may lead to producing different row orders in differentruns with identical data. The execution is non-deterministic.</p>
<p>Round Robinâ€“ picks rows from inputpartition patiently, for instance: first row from partition 0, next frompartition 1, even if other partitions can produce rows faster than partition 1.</p>
<p>Orderedâ€“ reads all rows from first partition, then secondpartition, then third and so on.</p>
<p>Sort Mergeâ€“ produces a globally sorted sequential streamfrom within partition sorted rows. Sort Merge produces a non-deterministic onun-keyed columns sorted sequential stream using the following algorithm: alwayspick the partition that produces the row with the smallest key value.Â </p>
<p></p>
 
we will cover these topics: 
<a class="lwptoc_toggle_label" data-label="show" href="index.html#">hide</a>



 <a href="index.html#Partitioning">
1)
Partitioning
</a>
 <a href="index.html#Ex">
2)
Ex:-
</a>
 <a href="index.html#EMP">
3)
EMP
</a>
 <a href="index.html#Repatriating">
4)
Repatriating
</a>
 <a href="index.html#Reverse_Partitioning">
4.1)
Reverse Partitioning
</a>
 <a href="index.html#Different_Collecting_Methods">
4.2)
Different Collecting Methods
</a>
 <a href="index.html#What_to_read_next">
4.3)
What to read next?
</a>

Partitioning
<p>It is a technique of distributing the records across the nodes, based on partitioning techniques.</p>

<ul><li>In addition, We have a 9thÂ technique known as â€˜AUTOâ€™</li></ul>
<p>Â Â NOTE:</p>
<ul><li>Partitioning techniques plays an important role in Performance Tuning</li></ul>
<p>Â Â Note:-</p>
<p>â€“ â€“ &gt; Key-based technique assures that the same key column values are collected at the same partition. Â </p>
Ex:-
<h2>Â EMP</h2>
<p>DNO= Primary key Â </p>
<table><tbody><tr><td>E NO</td><td>E Name</td><td>DNO</td></tr><tr><td>11</td><td>a</td><td>10</td></tr><tr><td>12</td><td>b</td><td>20</td></tr><tr><td>13</td><td>c</td><td>10</td></tr><tr><td>14</td><td>d</td><td>30</td></tr><tr><td>15</td><td>e</td><td>20</td></tr></tbody></table>
<table><tbody><tr><td>D NO</td><td>Â D Name</td><td>Â LocÂ </td></tr><tr><td>10</td><td>ACE</td><td>Hyd</td></tr><tr><td>20</td><td>Meter</td><td>Sec</td></tr><tr><td>30</td><td>Sales</td><td>Eng</td></tr></tbody></table>
<p>Â  When combine, I.e, using a horizontal combination</p>

<p>That is Same key column values are collected at the same partition Â </p>
<h2>Repatriating</h2>
<p>The Portioned data is once again repatriated</p>
<p>Ex:Â Â </p>
<table><tbody><tr><td>EName</td><td>Dno</td><td>Loc</td></tr><tr><td>A</td><td>10</td><td>AP</td></tr><tr><td>B</td><td>20</td><td>TN</td></tr><tr><td>C</td><td>10</td><td>TN</td></tr><tr><td>D</td><td>20</td><td>KN</td></tr><tr><td>E</td><td>30</td><td>TN</td></tr><tr><td>F</td><td>10</td><td>KN</td></tr><tr><td>G</td><td>20</td><td>AP</td></tr></tbody></table>

<ul><li>Partitioning and Repatriating are automatic processes in the Data stage</li></ul>
<h3>Â Â Reverse Partitioning</h3>
<ul><li>Reverse Partitioning is collecting the data from the nodes.</li><li>It happens only in 1 Situation that is Parallel to Sequential.</li></ul>

<p>Reverse Partitioning is also called as Collecting Â </p>
<h3>Different Collecting Methods</h3>
<ol><li>Ordered</li><li>Round Robin</li><li>Sort â€“ Merge</li><li>Auto</li></ol>

<br><br>
<h3>Meet Ananth Tirumanur. Hi there ğŸ‘‹</h3>

    <h4>I work on projects in data science, big data, data engineering, data modeling, software engineering, and system design.</h4>

    <ul>
        <li>ğŸ‘¨â€ğŸ’» All of my projects are available at <a href="https://github.com/akrish1982">https://github.com/akrish1982</a></li>
        <li>ğŸ’¬ Ask me about <strong>Data engineering, SQL, Databases, Data pipelines, Data infrastructure</strong></li>
        <li>ğŸ“„ My work history: <a href="https://www.linkedin.com/in/ananthtirumanur/">https://www.linkedin.com/in/ananthtirumanur/</a></li>
        <li>âš¡ Fun fact: Marathoner & Casual Birding enthusiast</li>
    </ul>

    <h3>Connect with me:</h3>
    <ul>
        <li>Twitter: <a href="https://twitter.com/akrish82">@akrish82</a></li>
        <li>LinkedIn: <a href="https://linkedin.com/in/ananthtirumanur/">https://linkedin.com/in/ananthtirumanur/</a></li>
    </ul>

<h3>My Resources:</h3>
    <ul>
        <li>LinkedIn Newsletter: <a href="https://www.linkedin.com/newsletters/data-engineering-with-aws-7096111313352880128/">Data Engineering with AWS</a></li>
        <li>Udemy Course: <a href="https://www.udemy.com/course/aws-certified-data-engineer-associate-practice-test/learn/quiz/6218524#overview">AWS Certified Data Engineer Associate Practice Test</a></li>
        <li>Python Crash Course: <a href="https://akrish82.gumroad.com/l/python-crash-course">Python Crash Course on Gumroad</a></li>
    </ul>

    <h3>Languages and Tools:</h3>
    <p>AWS, Bash, Docker, Elasticsearch, Git, Grafana, Hadoop, Hive, EMR, Glue, Athena, Lambda, Step Functions, Airflow/MWAA, DynamoDB, Kafka, Kubernetes, Linux, MariaDB, MySQL, Pandas, PostgreSQL, Python, Redis, Scala, SQLite</p>





 





 
 






