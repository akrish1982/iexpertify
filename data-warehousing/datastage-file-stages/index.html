<html><head><link href="/simplecss/styles.css" rel="stylesheet"/>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3040480045347797"
     crossorigin="anonymous"></script>
     <script
    src="https://topmate-embed.s3.ap-south-1.amazonaws.com/v1/topmate-embed.js"
    user-profile="https://topmate.io/embed/profile/ananth_tirumanur?theme=D5534D"
    btn-style='{"backgroundColor":"#000","color":"#fff","border":"1px solid #000"}'
    embed-version="v1"
    button-text="Let's Connect"
    position-right="30px"
    position-bottom="30px"
    custom-padding="0px"
    custom-font-size="16px"
    custom-font-weight="500"
    custom-width="200px"
    async=""
    defer=""
  ></script>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VS67BGEQZW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VS67BGEQZW');
</script>  
</head></html><!DOCTYPE html>
    <header>
        <nav>
            <ul>
                <li><a href="https://www.iexpertify.com/">iExpertify</a></li>
                <li><a href="https://www.iexpertify.com/free-utilities/">Free Utilities</a></li>
            </ul>
        </nav>
    </header>






DataStage File Stages - Data Warehousing Data Warehousing
Reading Time:  5 minutes
<p>File stages used to read and write data from files.Following are some common file stages used into DataStage.</p>
<p>Sequential File Stage</p>
<p>The sequential file Stage is a file Stage. It is the mostcommon I/O Stage used in a DataStage Job. It is used to read data from or writedata to one or more flat Files. It can have only one input link or one Outputlink. It can also have one reject link.</p>
<p>While handling huge volumes of data, this Stage can itselfbecome one of the major bottlenecks as reading and writing from this Stage isslow.</p>
<p>Sequential files should be used in following conditions Whenwe are reading a flat file (fixed width or delimited) from UNIX environment,which is FTPed from some external systems When some UNIX operations has to bedone on the file don‚Äôt use sequential file for intermediate storage betweenjobs. It causes performance overhead, as it needs to do data conversion beforewriting and reading from a UNIX file.</p>
<p>In order to have faster reading from the Stage the number ofreaders per node can be increased (default value is one).</p>
<p>Dataset Stage</p>
<p>The Data Set is a file Stage, which allows reading data fromor writing data to a dataset. This Stage can have a single input link or singleOutput link. It does not support a reject link.</p>
<p>It can be configured to operate in sequential mode orparallel mode. DataStage parallel extender jobs use Dataset to store data beingoperated on in a persistent form. Datasets are operating system files which byconvention has the suffix .ds Datasets are much faster compared to sequentialfiles. Data is spread across multiple nodes and is referred by a control file.</p>
<p>Datasets are not UNIX files and no UNIX operation can beperformed on them. Usage of Dataset results in a good performance in a set oflinked jobs. They help in achieving end-to-end parallelism by writing data inpartitioned form and maintaining the sort order.It also preserve partitions.</p>
<p>Dataset is having following parts:</p>
<p>Descriptor file: contains metadata, data location, but NOTthe data itself</p>
<p>Data file(s): Contains data in Native formatC:/IBM/Information Server / Server/data set/ file. Ds</p>
<p>Control file (or) header file : Resides in operating system.</p>
<p>File set stage</p>
<p>The File Set stage is a file stage. It allows you to readdata from or write data to a file set. The stage can have a single input link,a single output link, and a single rejects link.</p>
<p>It only executes in parallel mode. advantage of usingfileset over a sequential file is ‚Äúit preserves partitioning scheme‚Äù.¬†Theamount of data that can be stored in each destination data file is limited bythe characteristics of the file system and the amount of free disk spaceavailable. The number of files created by a file set depends on 1) the numberof processing nodes in the default node pool. 2)¬†The number of disks inthe export or default disk pool connected to each processing node in thedefault node pool. 3)¬†The size of the partitions of the data set.</p>
<p>Lookup file set stage</p>
<p>The Lookup File Set stage is a file stage. It allows you tocreate a lookup file set or reference one for a lookup.¬†The stage can havea single input link or a single output link. The output link must be areference link.¬†The stage can be configured to execute in parallel orsequential mode when used with an input link.</p>
<p>External source stage</p>
<p>The External Source stage is a file stage. It allows you toread data that is output from one or more source programs.¬†The stage callsthe program and passes appropriate arguments.¬†The stage can have a singleoutput link, and a single rejects link. It can be configured to execute inparallel or sequential mode.</p>
<p>External Target stage</p>
<p>The External Target stage is a file stage. It allows you towrite data to one or more source programs.¬†The stage can have a singleinput link and a single rejects link.¬†It can be configured to execute inparallel or sequential mode.</p>
<p>Complex Flat File stage</p>
<p>The Complex Flat File (CFF) stage is a file stage. You canuse the stage to read a file or write to a file, but you cannot use the samestage to do both.¬†As a source, the CFF stage can have multiple outputlinks and a single reject link. You can read data from one or more complex flatfiles, including MVS‚Ñ¢ data sets with QSAM and VSAM files. You can also readdata from files that contain multiple record types. The source data can containone or more of the following clauses:</p>
<p>v GROUP</p>
<p>v REDEFINES</p>
<p>v OCCURS</p>
<p>v OCCURS DEPENDING ON</p>
<p>CFF source stages run in parallel mode when they are used to read multiplefiles, but you can configure the stage to run sequentially if it is readingonly one file with a single reader.¬†</p>
<p>By using CFF, we can read ASCII or EBCDIC (Extended Binarycoded Decimal Interchage Code) data. We can select the required columns and canomit the remaining. We can collect the rejects (bad formatted records) bysetting the property of rejects to ‚Äúsave‚Äù (other options: continue,fail). We can flatten the arrays(COBOL files).</p>
<p>As a target, the CFF stage can have a single input link anda single reject link. You can write data to one or more complex flat files. Youcannot write to MVS data sets or to files that contain multiple record types.</p>

<br><br>
<h3>Meet Ananth Tirumanur. Hi there üëã</h3>

    <h4>I work on projects in data science, big data, data engineering, data modeling, software engineering, and system design.</h4>

    <ul>
        <li>üë®‚Äçüíª All of my projects are available at <a href="https://github.com/akrish1982">https://github.com/akrish1982</a></li>
        <li>üí¨ Ask me about <strong>Data engineering, SQL, Databases, Data pipelines, Data infrastructure</strong></li>
        <li>üìÑ My work history: <a href="https://www.linkedin.com/in/ananthtirumanur/">https://www.linkedin.com/in/ananthtirumanur/</a></li>
        <li>‚ö° Fun fact: Marathoner & Casual Birding enthusiast</li>
    </ul>
    <iframe height='160' width='300' frameborder='0' allowtransparency='true' scrolling='no' src='https://www.strava.com/athletes/42567926/activity-summary/6bbf7aabb6546e61f1317a54d973b259158da8a8'></iframe>


    <h3>Connect with me:</h3>
    <ul>
        <li>Twitter: <a href="https://twitter.com/akrish82">@akrish82</a></li>
        <li>LinkedIn: <a href="https://linkedin.com/in/ananthtirumanur/">https://linkedin.com/in/ananthtirumanur/</a></li>
    </ul>

<h3>My Resources:</h3>
    <ul>
        <li>LinkedIn Newsletter: <a href="https://www.linkedin.com/newsletters/data-engineering-with-aws-7096111313352880128/">Data Engineering with AWS</a></li>
        <li>Udemy Course: <a href="https://www.udemy.com/course/aws-certified-data-engineer-associate-practice-test/learn/quiz/6218524#overview">AWS Certified Data Engineer Associate Practice Test</a></li>
        <li>Python Crash Course: <a href="https://akrish82.gumroad.com/l/python-crash-course">Python Crash Course on Gumroad</a></li>
    </ul>

    <h3>Languages and Tools:</h3>
    <p>AWS, Bash, Docker, Elasticsearch, Git, Grafana, Hadoop, Hive, EMR, Glue, Athena, Lambda, Step Functions, Airflow/MWAA, DynamoDB, Kafka, Kubernetes, Linux, MariaDB, MySQL, Pandas, PostgreSQL, Python, Redis, Scala, SQLite</p>





 





 
 






