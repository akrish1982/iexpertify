<html><head><link href="/simplecss/styles.css" rel="stylesheet"/>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3040480045347797"
     crossorigin="anonymous"></script>
     <script
    src="https://topmate-embed.s3.ap-south-1.amazonaws.com/v1/topmate-embed.js"
    user-profile="https://topmate.io/embed/profile/ananth_tirumanur?theme=D5534D"
    btn-style='{"backgroundColor":"#000","color":"#fff","border":"1px solid #000"}'
    embed-version="v1"
    button-text="Let's Connect"
    position-right="30px"
    position-bottom="30px"
    custom-padding="0px"
    custom-font-size="16px"
    custom-font-weight="500"
    custom-width="200px"
    async=""
    defer=""
  ></script>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VS67BGEQZW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VS67BGEQZW');
</script>  
</head></html><!DOCTYPE html>
    <header>
        <nav>
            <ul>
                <li><a href="https://www.iexpertify.com/">iExpertify</a></li>
                <li><a href="https://www.iexpertify.com/free-utilities/">Free Utilities</a></li>
            </ul>
        </nav>
    </header>






DataStage Configuration File - Data Warehousing Data Warehousing
Reading Time:  4 minutes
<p>The Datastage configuration file is a master control file (atextfile which sits on the server side) for jobs which describes the parallelsystem resources and architecture. The configuration file provides hardwareconfiguration for supporting such architectures as SMP (Single machine withmultiple CPU , shared memory and disk), Grid , Cluster or MPP (multiple CPU,mulitple nodes and dedicated memory per node). DataStage understands thearchitecture of the system through this file.</p>
<p>This is one of the biggest strengths of Datastage. For casesin which you have changed your processing configurations, or changed servers orplatform, you will never have to worry about it affecting your jobs sinceall the jobs depend on this configuration file for execution. Datastage jobsdetermine which node to run the process on, where to store the temporary data,where to store the dataset data, based on the entries provide in theconfiguration file. There is a default configuration file available wheneverthe server is installed.</p>
<p>The configuration files have extension â€œ.aptâ€. Themain outcome from having the configuration file is to separate software andhardware configuration from job design. It allows changing hardware andsoftware resources without changing a job design. Datastage jobs can point todifferent configuration files by using job parameters, which means that a jobcan utilize different hardware architectures without being recompiled.</p>
<p>The general form of a configuration file is as follows:</p>
<p>Â  Â /* commentary */</p>
<p>Â  Â {</p>
<p>Â  Â  Â node â€œnode nameâ€ {</p>
<p>Â  Â  Â  Â  Â &lt;node information&gt;</p>
<p>Â  Â  Â  Â  .Â  Â </p>
<p>Â  Â  Â  Â  .</p>
<p>Â  Â  Â  Â  .</p>
<p>Â  Â  Â  }</p>
<p>Â  Â  Â .</p>
<p>Â  Â  Â .</p>
<p>Â  Â  Â .</p>
<p>Â  Â  }</p>
<p>What are the different options a logical node can have in the configurationfile?</p>
<p>1. Fastname â€“ The fastname is the physical node name thatstages use to open connections for high volume data transfers. The attribute ofthis option is often the network name. Typically, you can get this name byusing Unix command â€˜uname -nâ€™.</p>
<p>2.Â  Pools â€“ Name of the pools to which the node isassigned to. Based on the characteristics of the processing nodes you can groupnodes into set of pools. A pool can be associated with many nodes and a nodecan be part of many pools.</p>
<p>A node belongs to the default pool unless you explicitlyspecify pools list for it and omit the default pool name (â€œâ€) from the list.</p>
<p>3. Resource â€“ This will specify Specifies the location onyour server where the processing node will write all the data set files. As youmight know when Datastage creates a dataset, the file you see will not containthe actual data. The dataset file will actually point to the place where theactual data is stored. Now where the dataset data is stored is specified inthis line.</p>
<p>4. Resource scratchdisk â€“ The location of temporary filescreated during Datastage processes, like lookups and sorts will be specifiedhere. If the node is part of the sort pool then the scratch disk can also bemade part of the sort scratch disk pool. This will ensure that the temporaryfiles created during sort are stored only in this location. If such a pool isnot specified then Datastage determines if there are any scratch disk resourcesthat belong to the default scratch disk pool on the nodesÂ  that sort isspecified to run on. If this is the case then this space will be used.</p>
<p>Sample configuration file shown below</p>
<p>{</p>
<p>Â  Â node node1 {</p>
<p>Â  Â  Â  Â fastnameâ€œnode1_cssâ€Â  Â  Â  Â  Â  Â  Â  Â Â </p>
<p>Â  Â  Â  Â pools â€œâ€â€œnode1â€ â€œnode1_cssâ€Â  Â  Â  Â  Â </p>
<p>Â  Â  Â  Â resource diskâ€œ/orch/s0â€ {}</p>
<p>Â  Â  Â  Â resource scratchdiskâ€œ/scratch0â€ {pools â€œbufferâ€}</p>
<p>Â  Â  Â  Â resource scratchdiskâ€œ/scratch1â€ {}</p>
<p>Â  Â  Â  Â }</p>
<p>Â  Â node node2 {</p>
<p>Â  Â  Â  Â fastnameâ€œnode2_cssâ€Â  Â  Â  Â  Â  Â  Â  Â Â </p>
<p>Â  Â  Â  Â pools â€œâ€â€œnode2â€ â€œnode2_cssâ€Â  Â  Â  Â  Â </p>
<p>Â  Â  Â  Â resource diskâ€œ/orch/s0â€ {}</p>
<p>Â  Â  Â  Â resource scratchdiskâ€œ/scratch0â€ {pools â€œbufferâ€}</p>
<p>Â  Â  Â  Â resource scratchdiskâ€œ/scratch1â€ {}</p>
<p>Â  Â  Â  Â }</p>
<p>}</p>

<br><br>
<h3>Meet Ananth Tirumanur. Hi there ğŸ‘‹</h3>

    <h4>I work on projects in data science, big data, data engineering, data modeling, software engineering, and system design.</h4>

    <ul>
        <li>ğŸ‘¨â€ğŸ’» All of my projects are available at <a href="https://github.com/akrish1982">https://github.com/akrish1982</a></li>
        <li>ğŸ’¬ Ask me about <strong>Data engineering, SQL, Databases, Data pipelines, Data infrastructure</strong></li>
        <li>ğŸ“„ My work history: <a href="https://www.linkedin.com/in/ananthtirumanur/">https://www.linkedin.com/in/ananthtirumanur/</a></li>
        <li>âš¡ Fun fact: Marathoner & Casual Birding enthusiast</li>
    </ul>

    <h3>Connect with me:</h3>
    <ul>
        <li>Twitter: <a href="https://twitter.com/akrish82">@akrish82</a></li>
        <li>LinkedIn: <a href="https://linkedin.com/in/ananthtirumanur/">https://linkedin.com/in/ananthtirumanur/</a></li>
    </ul>

<h3>My Resources:</h3>
    <ul>
        <li>LinkedIn Newsletter: <a href="https://www.linkedin.com/newsletters/data-engineering-with-aws-7096111313352880128/">Data Engineering with AWS</a></li>
        <li>Udemy Course: <a href="https://www.udemy.com/course/aws-certified-data-engineer-associate-practice-test/learn/quiz/6218524#overview">AWS Certified Data Engineer Associate Practice Test</a></li>
        <li>Python Crash Course: <a href="https://akrish82.gumroad.com/l/python-crash-course">Python Crash Course on Gumroad</a></li>
    </ul>

    <h3>Languages and Tools:</h3>
    <p>AWS, Bash, Docker, Elasticsearch, Git, Grafana, Hadoop, Hive, EMR, Glue, Athena, Lambda, Step Functions, Airflow/MWAA, DynamoDB, Kafka, Kubernetes, Linux, MariaDB, MySQL, Pandas, PostgreSQL, Python, Redis, Scala, SQLite</p>





 





 
 






